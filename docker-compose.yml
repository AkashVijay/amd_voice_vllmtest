
services:
  vllm:
    image: rocm/vllm-dev:nightly
  
    devices:
      - /dev/kfd
      - /dev/dri
    security_opt:
      - seccomp:unconfined
    
    group_add:
      - "video"
      - "render"
    ipc: 
      "host"
    ports: 
      - "8000:8000"
    cap_add:
      - SYS_PTRACE
    environment: 
      HIP_VISIBLE_DEVICES: 4,5
      #ROCR_VISIBLE_DEVICES: 2

      # one of these makes it work and idk which ones
     # VLLM_SKIP_P2P_CHECK: 1
      #NCCL_CUMEM_ENABLE: 0
     # NCCL_IB_DISABLE: 1
     
      HSA_ENABLE_IPC_MODE_LEGACY: 0
      # why not have all of them 

      HF_HUB_CACHE: /hf_home

    volumes:
      - /shared/huggingface:/hf_home
    command: ["/bin/sh", 
              "-c", 
              "vllm serve Salesforce/Llama-xLAM-2-70b-fc-r --port 8000 --enforce-eager --gpu-memory-utilization 0.95 --tensor-parallel-size 2
              
              "]
              # 
               # 
      # --tensor-parallel-size 2
      # --max-model-len 74782
      #Salesforce/Llama-xLAM-2-70b-fc-r
  kokoro-fastapi:
    ports:
      - 8808:8808
    image: kokoro-fastapi-rocm
    devices:
      - /dev/kfd
      - /dev/dri
    security_opt:
      - seccomp:unconfined
    ipc: "host"
    # expose:
    #   - "8880"
    group_add:
      - "video"
      - "render"
      - "audio"
    cap_add:
      - SYS_PTRACE
    environment: 
      HIP_VISIBLE_DEVICES: 5
    restart: always
    command: ["python", "-m", "uvicorn", "api.src.main:app", "--host", "0.0.0.0", "--port", "8808", "--log-level", "debug"]

  open-webui:
    image: ghcr.io/open-webui/open-webui:main

    ports:
      - "8080:8080"

    volumes:
      - /home/akavijay/vllmtest/open-webui:/app/backend/data
    devices:
      - /dev/kfd
      - /dev/dri    
    environment:
      OPENAI_API_BASE_URL: http://vllm:8000/v1
      #ENABLE_OLLAMA_API: false
      AUDIO_TTS_OPENAI_API_BASE_URL: http://172.20.0.1:8808/v1

  mcp:
    build:
      context: .
      dockerfile: Dockerfile
    ports: 
      - "8008:8008"
    depends_on: 
      vllm:
        condition: service_started
    volumes:
      - /home/akavijay/vllmtest/db:/app/db
    command: ["mcpo", "--port", "8008", "--", "python", "server.py"]
